# -*- coding: utf-8 -*-
"""Test_Model.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1tYmfAMdOT4Jw7iPTXHugNlKTDlRd8v1A
"""

!git clone https://github.com/AssemblyAI-Examples/mediapipe-python.git
!pip install mediapipe
!pip install PyQt5
!pip install ipython==7.32.0
!pip install onnxruntime

import cv2 as cv
from mediapipe import solutions as mp
import time
import numpy as np
import onnxruntime as ort
from tensorflow.keras.models import load_model
from PIL import Image
import math

"""Prepare Image"""

def preprocess_image(image):
    hands = mp.hands.Hands()

    # Convert the image to RGB format
    image_rgb = cv.cvtColor(image, cv.COLOR_BGR2RGB)

    try:
        results = hands.process(image_rgb)
        if results.multi_hand_landmarks:
            x_values = []  # List to store X values of landmarks
            y_values = []
            for hand_landmarks in results.multi_hand_landmarks:
                for landmark_id, landmark in enumerate(hand_landmarks.landmark):
                    # Extracting X, Y, Z coordinates of each landmark
                    x = int(landmark.x * image.shape[1])
                    x_values.append(x)
                    y = int(landmark.y * image.shape[0])
                    y_values.append(y)
                    z = landmark.z  # Z coordinate may not be available in all cases

    except Exception as err:
        print(f"Error processing the image: {err}")

    mean_x = sum(x_values) / len(x_values)
    mean_y = sum(y_values) / len(y_values)

    furthest_distance = 0
    for x, y in zip(x_values, y_values):
        distance = math.sqrt((x - mean_x)**2 + (y - mean_y)**2)
        furthest_distance = max(furthest_distance, distance)

    # Calculate bounding box dimensions
    left = int(mean_x - furthest_distance - 10)
    top = int(mean_y - furthest_distance - 10)
    right = int(mean_x + furthest_distance + 10)
    bottom = int(mean_y + furthest_distance + 10)

    # Crop the image
    cropped_image = image[top:bottom, left:right]

    # Resize the image
    resized_image = cv.resize(image, (50, 50))

    # Convert to Array
    img_array = np.expand_dims(resized_image, axis=0)

    # Normalize pixel values from 0 to 1
    img_array = img_array / 255.0

    return img_array

# Path to image to test
image_path = "B.jpg"
test_img = cv.imread(image_path)
input_image = preprocess_image(test_img)

"""Test Image


"""

model = load_model('final_model.h5')

predictions = model.predict(input_image)
class_index = np.argmax(predictions)

print(f"Predicted Class Index: {class_index}")
map_characters1 = {0: 'A', 1: 'B', 2: 'C', 3: 'D', 4: 'E', 5: 'F', 6: 'G', 7: 'H', 8: 'I', 9: 'J', 10: 'K', 11: 'L', 12: 'M', 13: 'N', 14: 'O', 15: 'P', 16: 'Q', 17: 'R', 18: 'S', 19: 'T', 20: 'U', 21: 'V', 22: 'W', 23: 'X', 24: 'Y', 25: 'Z', 26: 'del', 27: 'nothing', 28: 'space'}
print(map_characters1[class_index])
combined_dict = dict(zip(map_characters1.values(), predictions[0]))

# Sort
sorted_items = sorted(combined_dict.items(), key=lambda x: x[1], reverse=True)
print(sorted_items)
# Print the top 3 items
top_3_items = sorted_items[:3]
for key, value in top_3_items:
  print(f"{key}: {value}")

correct_letter = "B"
letters = [key for key, _ in top_3_items]
correct = correct_letter in letters

print(correct)

"""Find Nodes"""

def find_nodes(image):
  mp_hands = mp.solutions.hands
  my_hand_drawing = mp.solutions.drawing_utils

  hands = mp_hands.Hands()

  # Flip the image
  # Have to switch colors because openCV color scheme is BGR not RGB
  image_rgb = cv.cvtColor(image, cv.COLOR_BGR2RGB)

  # Store the results
  start_time = time.time()
  try:
      results = hands.process(image_rgb)
  except Exception as err:
      print(f"Error processing the image: {err}")
  height, width, _ = image.shape

  # Create an empty image
  new_image = np.zeros((height, width, 3), dtype=np.uint8)  # Replace height and width with the desired image dimensions

  # Draw landmarks on the image
  for landmarks in results.multi_hand_landmarks:
          #Adds the landmarks (lines) on the hands
          my_hand_drawing.draw_landmarks(
          new_image,
          landmarks, mp_hands.HAND_CONNECTIONS
      )

  #new_image = cv.flip(new_image, 1)

  image_bgr = cv.cvtColor(cv.flip(image_rgb, 1), cv.COLOR_RGB2BGR)

  return new_image